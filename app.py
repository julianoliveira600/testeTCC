# C√ìDIGO CORRIGIDO PARA SALVAR O MODELO (MAIS COMPAT√çVEL)

import tensorflow as tf
import os
from google.colab import drive

print("--- INICIANDO PROCESSO DE CONVERS√ÉO E SALVAMENTO (VERS√ÉO COMPAT√çVEL) ---")

try:
    # Garante que o modelo existe na mem√≥ria
    if 'model' not in locals() and 'model' not in globals():
        raise NameError("A vari√°vel 'model' com o modelo treinado n√£o foi encontrada.")
    print("‚úÖ Modelo treinado ('model') encontrado na mem√≥ria.")
    
    # Monta o Drive e cria a pasta de destino
    drive.mount('/content/drive', force_remount=True)
    SAVE_DIR = '/content/drive/MyDrive/TCC/testeTCC-modelos-treinados/'
    os.makedirs(SAVE_DIR, exist_ok=True)
    print("‚úÖ Drive e pasta de destino prontos.")

    # --- IN√çCIO DA CORRE√á√ÉO ---
    # Caminho para o novo modelo
    TFLITE_MODEL_PATH = os.path.join(SAVE_DIR, 'modelo_compativel_quantizado.tflite')
    print(f"\nO novo modelo ser√° salvo em: {TFLITE_MODEL_PATH}")

    # Inicializa o conversor a partir do nosso modelo Keras
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    
    # APLICA A OTIMIZA√á√ÉO DE FAIXA DIN√ÇMICA (MAIS COMPAT√çVEL)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    
    # Removemos a linha "target_spec" que causava o problema de compatibilidade
    # converter.target_spec.supported_types = [tf.float16]
    
    # --- FIM DA CORRE√á√ÉO ---

    # Executa a convers√£o
    modelo_tflite_quantizado = converter.convert()
    print("‚úÖ Modelo convertido com sucesso.")

    # Salva o novo arquivo
    with open(TFLITE_MODEL_PATH, 'wb') as f:
        f.write(modelo_tflite_quantizado)
        
    print(f"\nüéâ SUCESSO! Novo modelo salvo com sucesso.")

    # Verifica√ß√£o final
    print("\nVerificando o arquivo na pasta de destino:")
    !ls -lh "{SAVE_DIR}"

except Exception as e:
    print(f"‚ùå Ocorreu um erro durante o processo: {e}")